from azureml.core.runconfig import (
    RunConfiguration,
    EnvironmentDefinition,
    CondaDependencies,
)

# Create environment file
cd = CondaDependencies.create()
cd.add_conda_package("numpy=1.16.2")
cd.add_conda_package("pandas=0.23.4")
cd.add_conda_package("lightgbm=2.3.0")
cd.save_to_file(base_directory="./", conda_file_path="myenv.yml")

print(cd.serialize_to_string())

# Create score file
import os
import json
import numpy as np
import pandas as pd
import lightgbm as lgb


def init():
    global bst
    model_root = os.getenv("AZUREML_MODEL_DIR")
    # The name of the folder in which to look for LightGBM model files
    lgbm_model_folder = "model"
    bst = lgb.Booster(
        model_file=os.path.join(model_root, lgbm_model_folder, "bst-model.txt")
    )


def run(raw_data):
    columns = bst.feature_name()
    data = np.array(json.loads(raw_data)["data"])
    test_df = pd.DataFrame(data=data, columns=columns)
    # Make prediction
    out = bst.predict(test_df)
    return out.tolist()

# Prepare features according to the input schema of the best model
train_dir = os.path.join(DATA_DIR, "train")
max_lag = int(parameter_values[parameter_values.index("--max-lag") + 1])
lags = np.arange(2, max_lag + 1)
window_size = int(parameter_values[parameter_values.index("--window-size") + 1])
used_columns = [
    "store",
    "brand",
    "week",
    "week_of_month",
    "month",
    "deal",
    "feat",
    "move",
    "price",
    "price_ratio",
]
GAP = 2
features, train_end_week = create_features(
    1, train_dir, lags, window_size, used_columns
)
test_fea = features[features.week >= train_end_week + GAP].reset_index(drop=True)
test_fea.drop("move", axis=1, inplace=True)

# Pick a few test data points
test_samples = json.dumps({"data": np.array(test_fea.iloc[:3]).tolist()})
test_samples = bytes(test_samples, encoding="utf8")

# Predict using the deployed model
result = service.run(input_data=test_samples)
print("prediction:", result)